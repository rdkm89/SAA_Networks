{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count and metric measure rankings\n",
    "\n",
    "Script for generating ranking statistics for Early Modern plays.\n",
    "\n",
    "NB: this script depends on the output from NetworkAnalysis.ipynb \n",
    "    &&\n",
    "    Plays need to have a .Gephi file with node metrics.\n",
    "    \n",
    "Long term goals:\n",
    "\n",
    "    -  Automate for full folder of plays.\n",
    "    -  Remove Gephi from the workflow and generate node stats using Networkx\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Preflight checks\n",
    "\n",
    "Import packages and define functions for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing required dependencies ['numpy']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b92dcc46a13f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#from os import listdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     raise ImportError(\n\u001b[0;32m---> 19\u001b[0;31m         \"Missing required dependencies {0}\".format(missing_dependencies))\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing required dependencies ['numpy']"
     ]
    }
   ],
   "source": [
    "# Import required packages, modules\n",
    "#import os\n",
    "#from os import listdir\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def list_xmlfiles(directory):\n",
    "    \"\"\"\n",
    "    Return a list of filenames ending in '.txt' in DIRECTORY.\n",
    "    Not strictly necessary but will be useful if we try to scale.\n",
    "    \"\"\"\n",
    "    xmlfiles = []\n",
    "    for filename in listdir(directory):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            xmlfiles.append(filename)\n",
    "    return xmlfiles\n",
    "\n",
    "def list_textfiles(directory):\n",
    "    \"\"\"\n",
    "    Return a list of filenames ending in '.txt' in DIRECTORY.\n",
    "    Not strictly necessary but will be useful if we try to scale.\n",
    "    \"\"\"\n",
    "    textfiles = []\n",
    "    for filename in listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            textfiles.append(filename)\n",
    "    return textfiles\n",
    "\n",
    "def count_totals(character_list):\n",
    "    \"\"\"\n",
    "    Function to count the total number of speech acts and lines per character in each play\n",
    "    \"\"\"\n",
    "    counts = []\n",
    "    \n",
    "    for character in list(unique):\n",
    "        lines = [[line.text for line in test(['l','p'])] for test in soup.findAll(who=character)]\n",
    "        words = [[word.replace('\\n', ' ').replace('\\r', '') for word in words] for words in lines]\n",
    "        #l = [[[((len(re.findall(r'\\w+', s)))) for s in i] for i in item] for item in words]\n",
    "        \n",
    "        x = []\n",
    "        for item in words:\n",
    "            for s in item:\n",
    "                x.append(len(re.findall(r'\\w+', s)))\n",
    "        \n",
    "        speech_acts = len(lines)\n",
    "        total_words = sum(x)\n",
    "        totals = (character, speech_acts, total_words)\n",
    "        counts.append(totals)\n",
    "        \n",
    "    df = pd.DataFrame(counts, columns=[\"character\", \"lines\", \"words\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def total_rankings(df):\n",
    "    \"\"\"\n",
    "    Create count rankings based on word and line lengths.\n",
    "    \"\"\"\n",
    "    df[\"line_rank\"] = df[\"lines\"].sort_values(ascending=False).rank(method='dense', ascending=False).astype(int)\n",
    "    df[\"word_rank\"] = df[\"words\"].sort_values(ascending=False).rank(method='dense', ascending=False).astype(int)\n",
    "    df[\"count_rank\"] = ((df[\"line_rank\"] + df[\"word_rank\"])/2).astype(int)\n",
    "    return df\n",
    "\n",
    "def metric_rankings(df):\n",
    "    \"\"\"\n",
    "    Create metrics rankings based on node metrics from .Gephi file\n",
    "    \n",
    "    I don't like this function very much. It's too pandas-y. But it works.\n",
    "    \"\"\"\n",
    "    df[\"WD_rank\"] = df[\"Weighted Degree\"].sort_values(ascending=False).rank(method='dense', ascending=False).astype(int)\n",
    "    df[\"EC_rank\"] = df[\"eigencentrality\"].sort_values(ascending=False).rank(method='dense', ascending=False).astype(int)\n",
    "    df[\"degree_rank\"] = df[\"Degree\"].sort_values(ascending=False).rank(method='dense', ascending=False).astype(int)\n",
    "    df[\"BC_rank\"] = df[\"betweenesscentrality\"].sort_values(ascending=False).rank(method='dense', ascending=False).astype(int)\n",
    "    df[\"metrics_rank\"] = ((df[\"WD_rank\"] + df[\"EC_rank\"] + df[\"degree_rank\"] + df[\"BC_rank\"])/4).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Calculate count measures\n",
    "\n",
    "First, we read in the Early Print XML play. Then we create idList, which is the list of all characters in the play. We then take the unique set of these characters and feed that into the count_totals function.\n",
    "\n",
    "This returns a dataframe called **_totals_** which contains a list of count measures for each character in the play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in plays and create BeautifulSoup object\n",
    "filename = \"/path/to/play.xml\"\n",
    "with open(filename, 'r') as file: \n",
    "    raw = file.read()\n",
    "    soup = BeautifulSoup(raw, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of characters based on lines\n",
    "idList = []\n",
    "for a in soup.findAll('sp'):\n",
    "    if 'who' in a.attrs.keys():\n",
    "        idList.append(a.attrs['who'])\n",
    "\n",
    "# Only unique characters\n",
    "unique = set(idList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count totals\n",
    "totals = count_totals(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b - Cleanup tables and rank measures\n",
    "\n",
    "There are still some errors in these tables that require a little fiddling around. The following lines are meant only as examples of the kind of cleaning up that can be (and has been) performed on the **_totals_** tables.\n",
    "\n",
    "The cleaned up **_totals_** table is then sent to the total_rankings function, returning a new dataframe called **_count-ranks_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove TCP string\n",
    "totals[\"character\"] = totals['character'].str.replace('A77565_01-','')\n",
    "# Change spellings and recount the totals\n",
    "totals[\"character\"] = totals[\"character\"].str.replace('phib','phebe')\n",
    "totals = totals.groupby('character').sum().reset_index()\n",
    "# Delete characters\n",
    "totals = totals.drop([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate + save count ranks\n",
    "count_ranks = total_rankings(totals)\n",
    "file1 = \"/path/to/ranked_counts.csv\"\n",
    "count_ranks.to_csv(file1, header=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Calculate metric measures\n",
    "\n",
    "We now import the table of node metrics generated using Gephi. This table is then sent to the **_metric_ranking_** function which returns a dataframe called **_metric-ranks_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "gephi = \"/Users/au564346/Desktop/gephi_metrics_brome.csv\"\n",
    "metrics = pd.read_csv(gephi)\n",
    "metrics = metrics[[\"Id\", \"Degree\", \"Weighted Degree\", \"eigencentrality\", \"betweenesscentrality\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for consistency\n",
    "len(metrics) == len(count_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Weighted Degree</th>\n",
       "      <th>eigencentrality</th>\n",
       "      <th>betweenesscentrality</th>\n",
       "      <th>WD_rank</th>\n",
       "      <th>EC_rank</th>\n",
       "      <th>degree_rank</th>\n",
       "      <th>BC_rank</th>\n",
       "      <th>metrics_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>careless</td>\n",
       "      <td>12</td>\n",
       "      <td>460</td>\n",
       "      <td>0.925220</td>\n",
       "      <td>75.828968</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wat</td>\n",
       "      <td>8</td>\n",
       "      <td>136</td>\n",
       "      <td>0.683085</td>\n",
       "      <td>6.917857</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saveall</td>\n",
       "      <td>8</td>\n",
       "      <td>104</td>\n",
       "      <td>0.714806</td>\n",
       "      <td>2.286111</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phebe</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>0.532772</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saleware</td>\n",
       "      <td>11</td>\n",
       "      <td>231</td>\n",
       "      <td>0.885730</td>\n",
       "      <td>17.880556</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prentice</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.259169</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>thrivewell</td>\n",
       "      <td>10</td>\n",
       "      <td>130</td>\n",
       "      <td>0.817535</td>\n",
       "      <td>10.562302</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lady</td>\n",
       "      <td>14</td>\n",
       "      <td>306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.581746</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>alicia</td>\n",
       "      <td>7</td>\n",
       "      <td>273</td>\n",
       "      <td>0.527759</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bellamie</td>\n",
       "      <td>8</td>\n",
       "      <td>166</td>\n",
       "      <td>0.673013</td>\n",
       "      <td>9.141667</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>closet</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>0.465839</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>crostill</td>\n",
       "      <td>8</td>\n",
       "      <td>121</td>\n",
       "      <td>0.711716</td>\n",
       "      <td>3.020635</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lovely</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>0.865653</td>\n",
       "      <td>20.534524</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bellamy_sr</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>0.653849</td>\n",
       "      <td>1.842857</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>page</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.163504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>servant</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.212364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fitzgerrard</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.326201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  Degree  Weighted Degree  eigencentrality  \\\n",
       "0      careless      12              460         0.925220   \n",
       "1           wat       8              136         0.683085   \n",
       "2       saveall       8              104         0.714806   \n",
       "3         phebe       6               42         0.532772   \n",
       "4      saleware      11              231         0.885730   \n",
       "5      prentice       3                6         0.259169   \n",
       "6    thrivewell      10              130         0.817535   \n",
       "7          lady      14              306         1.000000   \n",
       "8        alicia       7              273         0.527759   \n",
       "9      bellamie       8              166         0.673013   \n",
       "10       closet       5               81         0.465839   \n",
       "11     crostill       8              121         0.711716   \n",
       "13       lovely      11              174         0.865653   \n",
       "14   bellamy_sr       7               41         0.653849   \n",
       "15         page       2                2         0.163504   \n",
       "16      servant       2                4         0.212364   \n",
       "17  fitzgerrard       3               14         0.326201   \n",
       "\n",
       "    betweenesscentrality  WD_rank  EC_rank  degree_rank  BC_rank  metrics_rank  \n",
       "0              75.828968        1        2            2        1             1  \n",
       "1               6.917857        7        8            5        8             7  \n",
       "2               2.286111       10        6            5       10             7  \n",
       "3               0.991667       12       11            7       13            10  \n",
       "4              17.880556        4        3            3        4             3  \n",
       "5               0.444444       15       15            9       14            13  \n",
       "6              10.562302        8        5            4        5             5  \n",
       "7              34.581746        2        1            1        2             1  \n",
       "8               6.933333        3       12            6        7             7  \n",
       "9               9.141667        6        9            5        6             6  \n",
       "10              1.033333       11       13            8       12            11  \n",
       "11              3.020635        9        7            5        9             7  \n",
       "13             20.534524        5        4            3        3             3  \n",
       "14              1.842857       13       10            6       11            10  \n",
       "15              0.000000       17       17           10       15            14  \n",
       "16              0.000000       16       16           10       15            14  \n",
       "17              0.000000       14       14            9       15            13  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate + save ranked metric measures\n",
    "metric_ranks = metric_rankings(metrics)\n",
    "metric_ranks.to_csv(\"/path/to/ranked_metrics.csv\",\n",
    "             header=True, sep=\"\\t\")\n",
    "metric_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Combine tables\n",
    "\n",
    "Firstly, we create an abridged table which has only the average count and metrics rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save abridged ranks\n",
    "ranks = count_ranks.merge(metric_ranks, left_on='character', right_on='Id')\n",
    "ranks = ranks[[\"character\", \"count_rank\", \"metrics_rank\"]]\n",
    "ranks.to_csv(\"/paht/to/ranked.csv\",\n",
    "            header=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a larger table that brings together all of our desired metrics into a single table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ranks = count_ranks.merge(metric_ranks, left_on='character', right_on='Id')\n",
    "all_ranks = all_ranks[[\"character\", \"lines\", \"words\", \"Degree\", \"Weighted Degree\",\n",
    "                        \"eigencentrality\", \"betweenesscentrality\", \"line_rank\", \"word_rank\", \"degree_rank\", \n",
    "                           \"WD_rank\",\"BC_rank\", \"EC_rank\", \"count_rank\", \"metrics_rank\"]]\n",
    "all_ranks.to_csv(\"/path/to/complete_rankings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we calculate the Spearman's Rho on the average count and metric rankings, in order to see how they compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate + save spearman's rho\n",
    "corr = ranks.corr(method='spearman')\n",
    "corr.to_csv(\"/path/to/correlations.csv\",\n",
    "            header=True, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
