{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network extractor for Early Print plays\n",
    "\n",
    "<br>\n",
    "This script extracts weighted edgelists from plays for further analysis in Gephi.\n",
    "\n",
    "-  Characters share an edge through the \"speaking-in-turn\" principle - i.e. one character's speech follows another in the text. Adjacent pairs that occur across Act and Scene divisions are excluded.\n",
    "\n",
    "-  For this to work, the TEI-encoded plays must included appropriate speaker attributes. Specifically, each speaker tag ('sp') must the the 'who' attribute. \n",
    "\n",
    "-  This has been designed to work with plays form the Early Print corpus. However, this could be easily modified by making changes to the extract_all_characters function. From that point, everything else should work as normal.\n",
    "\n",
    "\n",
    "**NB:** _Somewhat disappointingly, not all Early Print plays have the appropriate annotation. This means that it is not possible to extract like-for-like edgelists for all plays._\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Preflight checks\n",
    "\n",
    "Importing packages and defining functions for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "\n",
    "def extract_all_characters(soup):\n",
    "    \"\"\"\n",
    "    Function to extract characters from XML file of a play.\n",
    "    \n",
    "    Extracts the value of two tag attributes\n",
    "    \n",
    "        One relates to Act/Scene divisions and the other is for \n",
    "        the name of the speaking character. These should be fairly\n",
    "        clear from the code.\n",
    "    \n",
    "    This function should be modified to deal with different XML schema.\n",
    "    \"\"\"\n",
    "    idList = []\n",
    "    for a in soup.findAll(['div', 'sp']):\n",
    "        if 'type' in a.attrs.keys():\n",
    "            idList.append(a.attrs['type'])\n",
    "        elif 'who' in a.attrs.keys():\n",
    "            idList.append(a.attrs['who'])\n",
    "    df = pd.DataFrame(idList, columns=['names'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def character_pairings_in(l):\n",
    "    \"\"\"\n",
    "    Function to create list of tuples of character pairings from extracted data\n",
    "    \n",
    "    This also (quite crudely) removes any Act or Scene divisions, which have all\n",
    "    been tagged using an asterisk.\n",
    "    \"\"\"\n",
    "    # Create list from Pandas DF\n",
    "    #l = dataframe[0].tolist()\n",
    "    # Create pairings from list\n",
    "    l2 = [(l[i],l[i+1]) for i in range(len(l)-1)]\n",
    "    # Remove all Act and Scene markers\n",
    "    x = [[t for t in a if not '#' in t] for a in l2]\n",
    "    # Keep only pairs of characters\n",
    "    y = [row for row in x if len(row) > 1]\n",
    "    # Create list of tuples\n",
    "    character_pairings = [tuple(l) for l in y]\n",
    "    \n",
    "    return character_pairings\n",
    "\n",
    "def create_edgelist_from(pairs):\n",
    "    \"\"\"\n",
    "    Function to create edgelists for \"speaking-in-turn\" pairs\n",
    "    \n",
    "    Returns results in a way that will be useful in Gephi\n",
    "    \"\"\"\n",
    "    # Create edgelist using defaultDict\n",
    "    edges = defaultdict(int)\n",
    "    for people in pairs:\n",
    "        for personA in people:\n",
    "            for personB in people:\n",
    "                if personA < personB:\n",
    "                    edges[personA + \",undirected,\" + personB] += 1\n",
    "    \n",
    "    # Create a dataframe from the defaultDict\n",
    "    df = pd.DataFrame.from_dict(edges, orient='index')\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    # Split cell on comma into muliple columns \n",
    "    split = (df['index'].str.split(',', expand=True).rename(columns=lambda x: f\"col{x+1}\"))\n",
    "    \n",
    "    # Merge these split columns with the 'weights' from the first df\n",
    "    merged = split.join(df[0])\n",
    "    \n",
    "    # Rename columns for use in Gephi\n",
    "    merged.columns = [\"Source\", \"Type\", \"Target\", \"Weight\"]\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Read in play and extract list of characters\n",
    "\n",
    "This creates a dataframe called **__character-list__**. This dataframe contains all textual divisions and character attributions in the order that they appear in the play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in play and create BeautifulSoup object\n",
    "filename = \"/path/to/play.xml\"\n",
    "with open(filename, 'r') as file: \n",
    "    raw = file.read()\n",
    "    soup = BeautifulSoup(raw, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list using extract function\n",
    "character_list = extract_all_characters(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Manual cleaning\n",
    "\n",
    "So far, I have been manually cleaning up some bits and pieces using a text editor. This should be automated for future work at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save externally for manual correction\n",
    "character_list.to_csv(\"/path/to/play.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Create edgelist\n",
    "\n",
    "This takes the manually cleaned list of character names and textual divisions and runs them through two functions. These have been strung togehter in a way that explains what they're doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This will not be necessary, if/when I can automate the cleanup process.\n",
    "data = pd.read_csv(\"/path/to/play.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If not reading in csv, change 'data' to idList in the following lines\n",
    "edgelist_df = create_edgelist_from(character_pairings_in(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "edgelist_df.to_csv(\"/path/to/edgelist.csv\", sep=\",\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** \n",
    "-  Create a main() function and iterate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
